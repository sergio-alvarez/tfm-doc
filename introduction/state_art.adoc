=== Estado del arte

El crecimiento exponencial de las redes sociales durante los últimos años ha despertado un gran interés en los diferentes ámbitos de la informática, siendo un claro objetivo comercial para profesionales del sector, así como un nuevo campo de investigación para los investigadores universitarios.

Como consecuencia de todo ello, durante los últimos años han ido apareciendo diversas aplicaciones que, de una u otra manera, se centran en estudiar ciertos aspectos de las redes sociales para poder extraer información acerca de sus usuarios gracias a las diversas publicaciones que estos mismos realizan en sus perfiles.

El estudio de la geolocalización de un usuario a partir de su contenido, sin embargo, es una de las pocas áreas que _tan sólo_ agrupa un pequeño número de estudios teóricos, pero en donde no han proliferado herramientas que comprueben de manera empírica los resultados teóricos emitidos por diversos investigadores.

Por ello, en este capítulo se recopilan algunos estudios teóricos y artículos de investigación que han servido como punto de arranque para este proyecto.

==== Estudios y artículos de investigación

Se pueden encontrar varias tendencias en la investigación de la geolocalización de los tuits y usarios de Twitter. Por un lado, existen investigadores que basan sus estudios en encontrar términos o entidades con significado geográfico propio, que se puedan cotejar con un gazetteerfootnote:[Conjunto de nombres geográficos que, junto con un mapa, constituye una importante referencia sobre lugares y sus nombres] con el objetivo de poder identificar nombres de lugares o coordenadas geográficas, intuyendo que aquellas que más veces aparezcan en el _timeline_ del usuario son aquellas más próximas a su localización real.

Por otro lado, otros investigadores han optado por estudiar únicamente el contenido de un tuit con el objetivo de encontrar aquellas palabras más características de un lugar y que puedan ser lo suficientemente discriminativas. En estos casos, se suele tender a buscar aquellos términos con una alta frecuencia y una baja dispersión geográfica.

Existen también enfoques donde se ha optado por una estrategia basada en estudiar el comportamiento de un usuario, utilizando técnicas de los dos métodos anteriores y combinándola con la información obtenida a través de servicios de terceros que puedan realizar publicaciones en el _timeline_ del usuario y además adjuntar información geolocalizada (*Foursquare* sería un claro ejemplo de este tipo de servicios).

===== Tweets from Justin Bieber’s Heart: The Dynamics of the "Location" Field in User Profiles
_Por Brent Hecht et al. Northwestern University y Palo Alto Research Center_

El estudio liderado por Brent Hecht demuestra de manera científica como el uso del campo de Localización disponible en los perfiles de los usuarios en Twitter no es un indicador válido para obtener su posición geográfica real.

Entre los datos obtenidos por Brent y su equipo se pueden destacar los siguientes:

. Sólo un 66% de los usuarios utiliza el campo de Localización para aportar información geográfica válida (es decir, localizaciones reales pero que *no tienen porqué indicar su situación real*. Por ejemplo, si una persona de *Oviedo* escribe *California* en el campo de Localización de su perfil, este estudio lo incluye dentro del 66% anterior).

. Algunos de los usos que los usuarios dentro del 34% restante aplican al campo de Localización se puede observar en <<location-use-type>>.

. La manera de distinguir entre localización real y ficticia supuso de un proceso manual en el que dos miembros del equipo debieron revisar tuit a tuit el campo de Localización, debido a la habilidad de los usuarios para poder expresar sarcasmo o ironía, así como expresiones comunes que pueden tener asociado un componente geográfico inherente (un ejemplo puede ser referirse al Principado de Asturias como _la tierrina_).

.Tipos de uso del campo de Localización por parte de los usuarios de Twitter
[cols="3,1", id="location-use-type"]
|===
|Cultura popular
|12.9%

|Referencias a su propia privacidad
|1.2%

|Insultos o contenido violento
|4.6%

|Localizaciones no terráqueas
|5.0%

|Emociones negativas hacia su localización real
|3.2%

|Naturaleza sexual
|3.2%
|===

Como alternativa a los resultados anteriores, y buscando una manera de automatizar el proceso y encontrar resultados más fiables y exhaustivos, se propusieron hacer un primer experimento para comprobar si el estudio de los contenidos publicados por un usuario pueden aportar la información necesaria para permitir inferir su ubicación geográfica.

Para ello, utilizaron un software de aprendizaje automático y un clasificador Bayesiano multinomial que en base a un conjunto de datos obtenidos a partir de aplicar el algoritmo _CALGARI_ (de implementación propia), fuese capaz de predecir a qué área (País y Estado) pertenece un tuit en base a su contenido.

[NOTE]
.CALGARI
====
El algoritmo CALGARI tiene como objetivo normalizar la frecuencia con la que un término ha aparecido dentro de un dataset de tuits para priorizar aquellos que son más específicas de un área (ciudad o estado) en concreto, penalizando palabras comunes como _ya, hola, adiós, etc._
====

Entre los resultados ofrecidos por el estudio destacan un *72.7% de acierto para inferir el país* de un usuario pero tan *sólo un 30% de acierto a nivel de estado*.

Como apunte adicional, es interesante una afirmación que se enuncia en el artículo cuando se hace referencia al nuevo campo de localización que la API Streaming de Twitter ofrece para adjuntar información geolocalizada (siempre que el usuario lo permita):

____
First, our focus is on the geographic information revealed in the “location” field of user profiles, a type of geographic information that is prevalent across the Web 2.0 world. *Second, we found that only 0.77% of our 62 million tweets contained this embedded location information*.
____

De 62 millones de tuits, únicamente un 0.77% (~= 477.400) contenían información geográfica adjunta.

===== Where Is This Tweet From? Inferring Home Locations of Twitter Users
_Por Jalal Mahmud et al. IBM Research_

Con el objetivo de poder identificar un tuit a diferentes granularidades: ciudad o estado, el estudio plantea la posibilidad de analizar tres tipos de términos diferentes para localizar una publicación en Twitter:

. *Palabras*
. *Hashtags*
. *Nombres de lugares* (utilizando un gazetteer geográfico). Puesto que estos términos podía estar compuestos por más de una palabra, se utilizaron bigramas y trigamas, así como un heurístico especializado en reconocer nombres de lugares expresados mediante vocabulario común (un ejemplo sería _Red Sox_ para referirse a la ciudad de Boston).

Es interesante observar como empiezan a aparecer pequeñas diferencias entre términos, considerando que en función de su categoría, pueden ofrecer más o menos información geográfica. Esta misma estrategia será también utilizada en el presente proyecto, mediante la extracción de Hashtags, Menciones y N-gramas.

Con el objetivo de minimizar la aparición de ruido, normalizaron el contenido de cada tuit eliminando signos de puntuación (a excepción de aquellos que indican una entidad propia cuando se encuentran al principio de una palabra, como `#` para indicar _hashtags_) y palabras vacías.

También se hace mención a la utilización de un *software de aprendizaje automático*, en este caso WEKA, y su conjunción con un modelo estadístico que realice los cálculos necesarios para el clasificador. El modelo que seleccionaron de manera empírica fue un clasificador Bayesiano multinomial.

La estrategia propuesta en este trabajo para inferir la localización de un usuario en Twitter fue:

. A lo largo de sus tuits, mencionará más veces su ciudad o estado de origen que el resto de ciudades o estados.
. Visitará más lugares de su ciudad o estado de origen que del resto de ciudades o estados (para detectar este tipo de visitas, se guardan todas las URLs generadas a partir de _check-ins_ compartidos a través de *Foursquare* para luego comprobar su información asociada a través de la propia API de Foursquare).

A partir de estas premisas y de las decisiones anteriores, se crearon 3 modelos diferentes para poder entrenar sobre cada uno de los términos que se quieren extraer: palabras, hashtags y nombres de lugares. Los resultados presentados a nivel de ciudad no fueron realmente positivos, y sólo presentan niveles de precisión superiores al 70% cuando se permiten márgenes de error superiores a 200 millas (~= 322 kilómetros).

Por último, no se especifica con exactitud cómo actúa realmente el algoritmo cuando se trabaja con usuarios que no tienen contenido generado por Foursquare o no hacen una referencia explícita a su ciudad, estado o país.

===== TweoLocator: A Non-Intrusive Geographical Locator System for Twitter
_Por Yi-Shin Chen et al. National Tsing Hua University_

En este estudio, Yi-Shin Chen diseña un sistema que a través de diferentes etapas y aglutinando varios procesos es capaz de inferir la localización de un usuario en Twitter en función del contenido de sus tuits.

Baseline Classification::

A partir de un gran dataset de usuarios de Twitter, en esta fase se realiza un análisis para comprobar qué perfiles puede ser potencialmente válidos para realizar un análisis de contenidos, eliminando aquellos que puedan pertenecer a _bots_ automáticos o sean perfiles de spam. Una vez se obtiene una masa de usuarios válidos se procede, dentro aún de esta etapa, a analizar todos sus tuits (a excepción de aquellos con información de geolocalización asociada) para volver a categorizarlos en 3 tipos:
* *Direct subject*: Tuits que hacen referencia al usuario en primera persona.
* *Anonymous subject*: Tuits que no hacen una referencia directa al usuario, pero utilizan otros pronombres personales o la primera secuencia de palabras es un verbo que no es una palabra vacía.
* *Others*: Tuits descartados por no pertenecer a ninguna de las 2 categorías anteriores.

Rule Generation::

Una vez todos los tuits anteriores han sido analizados semánticamente se realiza una normalización de los mismos aplicando técnicas de análisis de texto (utilizando un tokenizador y un stemmer) para luego poder formar n-gramas como los mismos. Durante esta etapa, se intentan inferir reglas que permitan asociar términos comunes a localizaciones específicas como aeropuertos, parques, estaciones de tren, etc.

Location Discovery::

A partir de los términos de cada tuit, se generan trigramas, bigramas y unigramas y se comparan sobre un gazetteer y las reglas generadas en el paso anterior, obteniendo localizaciones que se pueden agrupar en:

* *Explicit Specific*: Nombres que hacen una referencia directa a una ciudad o lugar determinado, como por ejemplo «The White House» or «Los Angeles».
* *Explicit*: Nombres que hacen referencia a localizaciones generales como parques o gimnasios.
* *Implicit*: Combinaciones de palabras que implícitamente sugieren una localización. Estos resultaos se obtienen a partir de las reglas generadas en el paso anterior.

Toponym Removal:: Mediante la utilización de un clúster, y partiendo de la premisa de que un usuario nombrará con mayor frecuencia lugares cercanos a su lugar de origen, en esta fase se analizan las menciones realizadas por el usuario sobre ciudades, lugares, países y se refinarán los datos para obtener su lugar de origen.

Timeline Sorting::

Es el último paso en el refinamiento de los datos. En esta fase se intenta minimizar la aparición de ruido detectando aquellas ocasiones en las que el usuario hace referencia a una localización geográfica sin aportar una información real acerca de su posición. Por ejemplo, es habitual que alguien situado en Asturias pueda nombrar la ciudad de Nueva York para hablar de alguna noticia o para mostrar sus ganas por conocer la ciudad, sin que esa mención indique que se encuentre realmente allí. Para resolver este problema, y aceptando que en algunos casos sólo se podrían resolver dichas inconsistencias de manera manual mediante la intervención humana, se diseñó un sistema que a partir de dos tuits con contenido geolocalizado consecutivos (del mismo usuario) compruebe si su diferencia en el tiempo es acorde a la posibilidad de haberse movido entre ambos puntos a una velocidad normal de transporte.

Location Inferred::

De acuerdo a los resultados obtenidos en todas las fases anteriores y de acuerdo al nivel sobre que el que se haya podido inferir su localización, los usuarios son clasificados en los siguientes grupos:

* *No information*: Si no se ha podido obtener información geográfica válida para inferir la localización del usuario.
* *Just country*: Si sólo se ha podido inferir el país del usuario.
* *Timeline*: Se han podido detectar ubicaciones actuales y previas del usuario, pero no su lugar de origen.
* *Hometown*: Se han podido detectar ubincaciones actuales y previas del usuario y *también* su lugar de origen. Es el grupo con información más completa.

En las conclusiones que se exponen en el artículo se muestran unos resultados bastante aceptables, donde hay porcentajes de acierto cercanos al 80%. Al igual que en el caso anterior, TweoLocator tiene una gran dependencia de que los usuarios incluyan en el contenido de sus tuits información explícitamente geolocalizable.

===== A Multi-Indicator Approach for Geolocalization of Tweets
_Por Axel Schulz et al. SAP Research_

En este artículo, un equipo de investigación de *SAP AG* presenta un enfoque muy interesante para inferir la localización de un usuario mediante la utilización de formas poligonales en 3D. Los polígonos se superponen, y la intersección de mayor altura es el área con más probabilidades de contener al usuario analizado.

La altura de cada polígono viene determinada por pesos específicos que se aplican en función de la fuente utilizada para obtener esa localización. Cada fuente tiene sus propios estándares de calidad y sus propias métricas para indicar más o menos fiabilidad.

Para obtener las coordenadas o posiciones geográficas que deben ocupar los polígonos, los investigadores extraen información de los siguientes campos:

Contenido del tuit::

Se optó por utilizar *DBPedia Spotlight* para extraer las entidades que existían en el tuit. Con los resultados de la extracción, se seleccionaban únicamente aquellas que tenían coordenadas asociadas. Además, se utilizó como calidad de cada predicción la propia confianza aportada por DBPedia Spotlight en su resultado. También se utilizaron las publicaciones realizadas a través de servicios como Foursquare, Flickr o Ubisoft, las cuales tienen adjunta información geográfica precisa mediante la utilización de coordenadas geográficas.

Localización::

Se hizo uso de gazetteers que permitiesen buscar coincidencias textuales en el campo de Localización. Además, se volvió a utilizar DBPedia Spotlight para conseguir trabajar con expresiones comunes como «La gran manzana» y expresiones regulares para detectar si algún usuario incluía coordenadas geográficas directamente en su campo de Localización.

Web del usuario::

Para aquellos usuarios que añaden en su perfil su página web personal se aplican dos estrategias:

. Extraer el dominio de la página (.com, .es, etc).
. Utilizar la dirección IP y obtener las coordenadas a través del servicio IPInfoDB.

Zona horaria::

Se asume como cierto que la zona horaria asociada al usuario es la capital de su país de origen.

Los resultados de este estudio presentan mejorías respecto a otras investigaciones basadas en inferir la localidad de un usuario mediante el uso de *múltiples indicadores* con un 37% de acierto con una distancia de error de 10km y un 48% para 25km; así como un 54% cuando el margen se amplía a 50km.

===== Inferring the Origin Locations of Tweets with Quantitative Confidence
_Por Reid Priedhorsky et al. Los Alamos National Laboratory y Northeastern Illinois University_

El artículo parte de la premisa de que no es posible obtener la localización de un tuit con una exactitud total, si no que lo más acertado es ofrecer un modelo probabilístico que muestre las diferentes localizaciones a las que un tuit puede pertenecer asociadas a un grado de confianza (probabilidad).

Para obtener un dataset de entrenamiento, se utilizó la API Streaming de Twitter para después realizar un procesamiento de cada tuit extrayendo información de los campos: descripción del usuario, idioma del perfil seleccionado, campo de localización, zona horaria y contenido del tuit. Sobre esta información, se extrajeron bigramas para todos los términos adyacentes (a excepción del campo de zona horaria). Además, también se almacenó la información geográfica adjunta al tuit para poder realizar los experimentos y el entrenamiento del modelo.

Un ejemplo de la extracción de bigramas sería:

____
Obviamente todo esto se hace para acabar con la costumbre de nuestra infancia de los álbumes de cromos.
____

Que se traduciría a:

____
Obviamente todo, todo esto, esto se, se hace, hace para, para acabar, acabar con, con la, la costumbre, costumbre de, de nuestra, nuestra infancia, infancia de, de los, los álbumes, álbumes de, de cromos.
____

Una vez con toda esta información almacenada, se utilizó una técnica de estimación denominada «gaussian mixture models» en donde cada bigrama que aparezca más de un mínimo número de veces se asocia a las coordenadas del tuit que lo contiene. Cada asociación, va vinculada a un peso específico en función del bigrama y la suma de todos los pesos asociados a un tuit es su probabilidad total de pertenecer a esas coordenadas.

Para calcular el peso que se le debe dar a cada a cada bigrama, el equipo de Reid Priedhorsky desarrolló tres métodos diferentes:

* Peso por propiedades de calidad
* Peso por error inverso
* Peso por optimización

Todos ellos con una alta dosis de componente algorítmico y matemático.

Los resultados del estudio revelaron un acierto del 83% para aquellos tuits que contenían bigramas con contenido explícitamente localizable (nombres de lugares) frente a un 57% de acierto sobre tuits sin información geográfica.

===== You Are Where You Tweet: A Content-Based Approach to Geo-locating Twitter Users
_Por Zhiyuan Cheng et al. Texas A&M University_

En este estudio, Zhiyuan Cheng y su equipo aportan datos interesantes en la investigación de la geolocalización en Twitter. Centrados en buscar un algoritmo capaz de inferir la localización de un usuario *únicamente* con el contenido de sus tuits, establecen tres criterios que serán ampliamente utilizados por el resto de investigaciones posteriores:

1. Se deben buscar términos con un fuerte componente discriminativo mediante la aplicación de algoritmos que sirvan para normalizar la frecuencia de apariciones de un término.

2. El test Likelihood ratio es capaz de obtener probabilidades bastante acertadas para este dominio específico.

3. Los términos más altamente discriminativos se caracterizan por una alta frecuencia y una baja dispersión.

Entre los resultados que presentaron, afirman ser capaces de localizar correctamente el 51% de los tuits dentro de un radio de error de 100 millas (~= 161 km.).

===== Otros _papers_ de interés

* *Location Type Classification Using Tweet Content* _por Haibin Liu et al. The Pennsylvania State University_
* *TweetLocalize: Inferring Author Location in Social Media* _por Evan Sparks et al. University of California-Berkeley_
* *Inferring the Location of Twitter Messages Based on User Relationships* _por Clodoveu A. Davis Jr. et al. Universidade Federal de Minas Gerais_
* *Geolocation Prediction in Social Media Data by Finding Location Indicative Words* _por HAN Bo et al. University of Melbourne_
* *Home Location Identification of Twitter Users* _por Jalal Mahmud et al. IBM Research_
* *Geotagging One Hundred Million Twitter Accounts with Total Variation Minimization* _por Ryan Compton et al. HRL Laboratories (Malibu)_
