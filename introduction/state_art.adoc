=== Estado del arte

Desde la aparición de Twitter en 2006 y su irrupción como servicio de masas en torno al año 2008, han ido apareciendo de manera exponencial diferentes servicios y vías de investigación centradas en estudiar el comportamiento de los usuarios en la red social en base a sus publicaciones, con el objetivo de poder extraer conclusiones acerca de su tendencia política, opiniones personales y otras características individuales.

[NOTE]
.Twitter
====
Twitter es una red social (también clasificada como servicio de _microblogging_) creada en 2006 por Jack Dorsey. Su principal característica es el envío de posts de 140 caracteres por parte de los usuarios y la capacidad de que estos mismos formen su propio _timeline_ suscribiéndose a las publicaciones realizadas por el resto de usuarios.
====

Sin embargo, un problema habitual a la hora de trabajar con datos extraídos de Twitter es su falta de estructuración. Si bien es habitual que los usuarios en redes sociales como Facebook mantengan un perfil completo y actualizado con datos reales (en parte gracias al buen hacer de dicha red social por conseguir que así sea), en Twitter lo más habitual es carecer de dicha información. Por tanto, muchos de los esfuerzos realizados en el análisis de contenidos en Twitter vienen para cubrir esa necesidad de obtener información real acerca de los usuarios que realizan las publicaciones.

Por poner un ejemplo, la figura <<fb-profile>> muestra una captura del perfil del autor en Facebook. En ella, se puede observar como aparece una gran cantidad de información perfectamente estructurada: centros de estudio, lugar de nacimiento, lugar de residencia actual, fecha de nacimiento, sexo e incluso campos que, aunque en este caso no estén completos, podrían aportar muchísima más información sobre el usuario: relación sentimental, ideología política o religiosa, etc.

.Captura del perfil del autor en Facebook
image::introduction/fb_profile.png[id="fb-profile",align="center"]

Sin embargo, los perfiles en Twitter son muchísimo más limitados. Por utilizar el mismo símil, la figura <<twitter-profile>> muestra una captura del perfil del autor en Twitter. Como se puede observar, en este caso tan sólo se muestra una pequeña biografía en la que el usuario aprovecha para reflejar su perfil más profesional.

.Captura del perfil del autor en Twitter
image::introduction/twitter_profile.png[id="twitter-profile",height="200px",align="center"]

En el caso de la geolocalización de usuarios, Bren Hercht _et al._ en su artículo *Tweets from Justin Bieber’s Heart: The Dynamics of the "Location" Field in User Profiles*, centrado en estudiar el campo de *Localización* de los perfiles de usuario, realiza la siguiente afirmación acerca de la cantidad de tuits geoposicionados (es decir, con información geográfica adjunta como latitud y longitud) que contenían en su dataset de ejemplo:

____
First, our focus is on the geographic information revealed in the “location” field of user profiles, a type of geographic information that is prevalent across the Web 2.0 world. *Second, we found that only 0.77% of our 62 million tweets contained this embedded location information*.
____

De 62 millones de tuits, únicamente un 0.77% (~= 477.400) contenían información geográfica adjunta. Como se puede deducir de esta afirmación, el problema para geolocalizar usuarios en Twitter es real y su solución sería de gran interés para poder contribuir a un mejor estudio de las publicaciones de los usuarios en la red social, obteniendo la capacidad de situarlos en un espacio geográfico concreto.

A continuación, se recogen una serie de artículos de investigación que abordan la problemática anterior y proponen mecanismos para inferir la localización de un usuario en base al contenido de sus publicaciones.

==== Estudios y artículos de investigación

Se pueden encontrar varias tendencias en la investigación de la geolocalización de los tuits y usuarios de Twitter. Por un lado, existen investigadores que basan sus estudios en encontrar términos o entidades con significado geográfico propio, que se puedan cotejar con un gazetteer con el objetivo de poder identificar nombres de lugares o coordenadas geográficas, intuyendo que aquellas que más veces aparezcan en el _timeline_ del usuario son aquellas más próximas a su localización real.

[NOTE]
.Timeline de Twitter
====
El timeline de un usuario en Twitter se puede entender como la vista principal del usuario en la que puede observar, en tiempo real, las publicaciones realizadas por aquellos usuarios a los que está suscrito (o a los que _sigue_, si se prefiere utilizar la terminología propuesta por Twitter).
====

Por otro lado, grupos de investigadores han optado por estudiar únicamente el contenido de un tuit con el objetivo de encontrar aquellas palabras más características de un lugar y que puedan ser lo suficientemente discriminativas. En estos casos, se suele tender a buscar aquellos términos con una alta frecuencia y una baja dispersión geográfica.

[NOTE]
.Gazetteer
====
Un gazetteer (o *nomenclátor* en español) es un diccionario geográfico que contiene los nombres de varias localizaciones geográficas referentes a un lugar. Por lo general, es habitual disponer de gazetteers a nivel de país para indicar el conjunto de sus ciudades, comunidades autónomas o provincias. Así como para casi cualquier otra unidad administrativa.
====

Existen también enfoques donde se ha optado por una estrategia basada en estudiar el comportamiento de un usuario, utilizando técnicas de los dos métodos anteriores y combinándola con la información obtenida a través de servicios de terceros que puedan realizar publicaciones en el _timeline_ del usuario y además adjuntar información geolocalizada (*Foursquare* sería un claro ejemplo de este tipo de servicios).

[NOTE]
.Foursquare
====
Foursquare es una aplicación desarrollada originalmente para dispositivos móviles, que funciona en parte con las características propias de cualquier red social, permitiendo a cada usuario publicar su ubicación actual al resto de sus contactos. A diferencia de otras redes sociales más generales (como Facebook o Twitter), Foursquare tiene como objetivo compartir localizaciones concretas que tienen adjunta información geográfica. Su explosión como servicio se basó en su interoperabilidad con el resto de servicios como Facebook, Twitter o Google+ permitiendo que las publicaciones en Foursquare se pueden observar desde el resto de redes sociales del usuario.
====

===== Tweets from Justin Bieber’s Heart: The Dynamics of the "Location" Field in User Profiles
_Por Brent Hecht et al. Northwestern University y Palo Alto Research Center_

El estudio liderado por Brent Hecht demuestra como el uso del campo de Localización disponible en los perfiles de los usuarios en Twitter no es un indicador válido para obtener su posición geográfica real.

Entre los datos obtenidos por Brent y su equipo se pueden destacar los siguientes:

. Sólo un 66% de los usuarios utiliza el campo de Localización para aportar información geográfica válida (es decir, localizaciones reales pero que *no tienen porqué indicar su situación real*. Por ejemplo, si una persona de *Oviedo* escribe *California* en el campo de Localización de su perfil, este estudio lo incluye dentro del 66% anterior).

. Algunos de los usos que los usuarios dentro del 34% restante aplican al campo de Localización se puede observar en <<location-use-type>>.

. La manera de distinguir entre localización real y ficticia supuso de un proceso manual en el que dos miembros del equipo debieron revisar tuit a tuit el campo de Localización, debido a la habilidad de los usuarios para poder expresar sarcasmo o ironía, así como expresiones comunes que pueden tener asociado un componente geográfico inherente (un ejemplo puede ser referirse al Principado de Asturias como _la tierrina_).

.Tipos de uso del campo de Localización por parte de los usuarios de Twitter
[cols="3,1", id="location-use-type"]
|===
|Cultura popular
|12.9%

|Referencias a su propia privacidad
|1.2%

|Insultos o contenido violento
|4.6%

|Localizaciones no terráqueas
|5.0%

|Emociones negativas hacia su localización real
|3.2%

|Naturaleza sexual
|3.2%
|===

Como alternativa a los resultados anteriores, y buscando una manera de automatizar el proceso y encontrar resultados más fiables y exhaustivos, se propusieron hacer un primer experimento para comprobar si el estudio de los contenidos publicados por un usuario pueden aportar la información necesaria para permitir inferir su ubicación geográfica.

[NOTE]
.Clasificador Bayesiano
====
De manera simplificada, se podría definir un *clasificador Bayesiano* como un clasificador probabilístico basado en el teorema de Bayes, que permite trabajar con una serie de características de manera independiente, sin asumir que la ausencia o presencia de cada una influya en el valor que se otorga a las demás para calcular la predicción final.
====

Para ello, utilizaron un software de aprendizaje automático y un *clasificador Bayesiano* multinomial que en base a un conjunto de datos obtenidos a partir de aplicar el algoritmo _CALGARI_ (de implementación propia), fuese capaz de predecir a qué área (País y Estado) pertenece un tuit en base a su contenido.

[NOTE]
.CALGARI
====
El algoritmo CALGARI tiene como objetivo normalizar la frecuencia con la que un término ha aparecido dentro de un dataset de tuits para priorizar aquellos que son más específicas de un área (ciudad o estado) en concreto, penalizando palabras comunes como _ya, hola, adiós, etc._
====

Entre los resultados ofrecidos por el estudio destacan un *72.7% de precisión para inferir el país* de un usuario pero tan *sólo un 30% de precisión a nivel de estado*.

===== Where Is This Tweet From? Inferring Home Locations of Twitter Users
_Por Jalal Mahmud et al. IBM Research_

Con el objetivo de poder identificar un tuit a diferentes granularidades: ciudad o estado, el estudio plantea la posibilidad de analizar tres tipos de términos diferentes para localizar una publicación en Twitter:

. *Palabras*
. *Hashtags*
. *Nombres de lugares* (utilizando un gazetteer geográfico). Puesto que estos términos podía estar compuestos por más de una palabra, se utilizaron bigramas y trigamas, así como un heurístico especializado en reconocer nombres de lugares expresados mediante vocabulario común (un ejemplo sería _Red Sox_ para referirse a la ciudad de Boston).

[NOTE]
.Hashtag
====
Un hashtag es un término que comienza con el literal `#` y sirve para categorizar el contenido de un tuit.
====

Es interesante observar como empiezan a aparecer pequeñas diferencias entre términos, considerando que en función de su categoría, pueden ofrecer más o menos información geográfica. Esta misma estrategia será también utilizada en el presente proyecto, mediante la extracción de Hashtags, Menciones y N-gramas.

Con el objetivo de minimizar la aparición de ruido, normalizaron el contenido de cada tuit eliminando signos de puntuación (a excepción de aquellos que indican una entidad propia cuando se encuentran al principio de una palabra, como `#` para indicar _hashtags_) y palabras vacías.

También se hace mención a la utilización de un *software de aprendizaje automático*, en este caso WEKA, y su conjunción con un modelo estadístico que realice los cálculos necesarios para el clasificador. El modelo que seleccionaron de manera empírica fue un clasificador Bayesiano multinomial.

[NOTE]
.WEKA
====
WEKA es una implementación de software de aprendizaje automático realizada en Java por la Universidad de Waikato en Nueva Zelanda. Es uno de los sistemas más utilizados debido a su soporte para aplicar un gran número de algoritmos de aprendizaje automático.
====

La estrategia propuesta en este trabajo para inferir la localización de un usuario en Twitter fue:

. A lo largo de sus tuits, mencionará más veces su ciudad o estado de origen que el resto de ciudades o estados.
. Visitará más lugares de su ciudad o estado de origen que del resto de ciudades o estados (para detectar este tipo de visitas, se guardan todas las URLs generadas a partir de _check-ins_ compartidos a través de *Foursquare* para luego comprobar su información asociada a través de la propia API de Foursquare).

A partir de estas premisas y de las decisiones anteriores, se crearon 3 modelos diferentes para poder entrenar sobre cada uno de los términos que se quieren extraer: palabras, hashtags y nombres de lugares. Los resultados presentados a nivel de ciudad no fueron realmente positivos, y sólo presentan niveles de precisión superiores al 70% cuando se permiten márgenes de error superiores a 200 millas (~= 322 kilómetros).

Por último, no se especifica con exactitud cómo actúa realmente el algoritmo cuando se trabaja con usuarios que no tienen contenido generado por Foursquare o no hacen una referencia explícita a su ciudad, estado o país.

===== TweoLocator: A Non-Intrusive Geographical Locator System for Twitter
_Por Yi-Shin Chen et al. National Tsing Hua University_

En este estudio, Yi-Shin Chen diseña un sistema que a través de diferentes etapas y aglutinando varios procesos es capaz de inferir la localización de un usuario en Twitter en función del contenido de sus tuits.

Clasificación base::

A partir de un gran dataset de usuarios de Twitter, en esta fase se realiza un análisis para comprobar qué perfiles puede ser potencialmente válidos para realizar un análisis de contenidos, eliminando aquellos que puedan pertenecer a _bots_ automáticos o sean perfiles de spam. Una vez se obtiene una masa de usuarios válidos se procede, dentro aún de esta etapa, a analizar todos sus tuits (a excepción de aquellos con información de geolocalización asociada) para volver a categorizarlos en 3 tipos:
* *Direct subject*: Tuits que hacen referencia al usuario en primera persona.
* *Anonymous subject*: Tuits que no hacen una referencia directa al usuario, pero utilizan otros pronombres personales o la primera secuencia de palabras es un verbo que no es una palabra vacía.
* *Others*: Tuits descartados por no pertenecer a ninguna de las 2 categorías anteriores.

Generación de reglas::

Una vez todos los tuits anteriores han sido analizados semánticamente se realiza una normalización de los mismos aplicando técnicas de análisis de texto (utilizando un tokenizador y un stemmer) para luego poder formar n-gramas como los mismos. Durante esta etapa, se intentan inferir reglas que permitan asociar términos comunes a localizaciones específicas como aeropuertos, parques, estaciones de tren, etc.

Descubrimiento de localizaciones::

A partir de los términos de cada tuit, se generan trigramas, bigramas y unigramas y se comparan sobre un gazetteer y las reglas generadas en el paso anterior, obteniendo localizaciones que se pueden agrupar en:

* *Explicit Specific*: Nombres que hacen una referencia directa a una ciudad o lugar determinado, como por ejemplo «The White House» o «Los Ángeles».
* *Explicit*: Nombres que hacen referencia a localizaciones generales como parques o gimnasios.
* *Implicit*: Combinaciones de palabras que implícitamente sugieren una localización. Estos resultaos se obtienen a partir de las reglas generadas en el paso anterior.

Eliminación de topónimos:: Mediante la utilización de un clúster, y partiendo de la premisa de que un usuario nombrará con mayor frecuencia lugares cercanos a su lugar de origen, en esta fase se analizan las menciones realizadas por el usuario sobre ciudades, lugares, países y se refinarán los datos para obtener su lugar de origen.

Ordenación temporal::

Es el último paso en el refinamiento de los datos. En esta fase se intenta minimizar la aparición de ruido detectando aquellas ocasiones en las que el usuario hace referencia a una localización geográfica sin aportar una información real acerca de su posición. Por ejemplo, es habitual que alguien situado en Asturias pueda nombrar la ciudad de Nueva York para hablar de alguna noticia o para mostrar sus ganas por conocer la ciudad, sin que esa mención indique que se encuentre realmente allí. Para resolver este problema, y aceptando que en algunos casos sólo se podrían resolver dichas inconsistencias de manera manual mediante la intervención humana, se diseñó un sistema que a partir de dos tuits con contenido geolocalizado consecutivos (del mismo usuario) compruebe si su diferencia en el tiempo es acorde a la posibilidad de haberse movido entre ambos puntos a una velocidad normal de transporte.

Localización inferida::

De acuerdo a los resultados obtenidos en todas las fases anteriores y de acuerdo al nivel sobre que el que se haya podido inferir su localización, los usuarios son clasificados en los siguientes grupos:

* *No information*: Si no se ha podido obtener información geográfica válida para inferir la localización del usuario.
* *Just country*: Si sólo se ha podido inferir el país del usuario.
* *Timeline*: Se han podido detectar ubicaciones actuales y previas del usuario, pero no su lugar de origen.
* *Hometown*: Se han podido detectar ubicaciones actuales y previas del usuario y *también* su lugar de origen. Es el grupo con información más completa.

En las conclusiones que se exponen en el artículo se muestran unos resultados bastante aceptables, donde hay porcentajes de precisión cercanos al 80%. Al igual que en el caso anterior, TweoLocator tiene una gran dependencia de que los usuarios incluyan en el contenido de sus tuits información explícitamente geolocalizable.

===== A Multi-Indicator Approach for Geolocalization of Tweets
_Por Axel Schulz et al. SAP Research_

En este artículo, un equipo de investigación de *SAP AG* presenta un enfoque muy interesante para inferir la localización de un usuario mediante la utilización de formas poligonales en 3D. Los polígonos se superponen, y la intersección de mayor altura es el área con más probabilidades de contener al usuario analizado.

La altura de cada polígono viene determinada por pesos específicos que se aplican en función de la fuente utilizada para obtener esa localización. Cada fuente tiene sus propios estándares de calidad y sus propias métricas para indicar más o menos fiabilidad.

Para obtener las coordenadas o posiciones geográficas que deben ocupar los polígonos, los investigadores extraen información de los siguientes campos:

Contenido del tuit::

Se optó por utilizar *DBPedia Spotlight* para extraer las entidades que existían en el tuit. Con los resultados de la extracción, se seleccionaban únicamente aquellas que tenían coordenadas asociadas. Además, se utilizó como calidad de cada predicción la propia confianza aportada por DBPedia Spotlight en su resultado. También se utilizaron las publicaciones realizadas a través de servicios como Foursquare, Flickr o Ubisoft, las cuales tienen adjunta información geográfica precisa mediante la utilización de coordenadas geográficas.

Localización::

Se hizo uso de gazetteers que permitiesen buscar coincidencias textuales en el campo de Localización. Además, se volvió a utilizar DBPedia Spotlight para conseguir trabajar con expresiones comunes como «La gran manzana» y expresiones regulares para detectar si algún usuario incluía coordenadas geográficas directamente en su campo de Localización.

Web del usuario::

Para aquellos usuarios que añaden en su perfil su página web personal se aplican dos estrategias:

. Extraer el dominio de la página (.com, .es, etc).
. Utilizar la dirección IP y obtener las coordenadas a través del servicio IPInfoDB.

Zona horaria::

Se asume como cierto que la zona horaria asociada al usuario es la capital de su país de origen.

Los resultados de este estudio presentan mejorías respecto a otras investigaciones basadas en inferir la localidad de un usuario mediante el uso de *múltiples indicadores* con un 37% de precisión con una distancia de error de 10km y un 48% para 25km; así como un 54% cuando el margen se amplía a 50km.

===== Inferring the Origin Locations of Tweets with Quantitative Confidence
_Por Reid Priedhorsky et al. Los Alamos National Laboratory y Northeastern Illinois University_

El artículo parte de la premisa de que no es posible obtener la localización de un tuit con una exactitud total, sino que lo más acertado es ofrecer un modelo probabilístico que muestre las diferentes localizaciones a las que un tuit puede pertenecer asociadas a un grado de confianza (probabilidad).

Para obtener un dataset de entrenamiento, se utilizó la API Streaming de Twitter para después realizar un procesamiento de cada tuit extrayendo información de los campos: descripción del usuario, idioma del perfil seleccionado, campo de localización, zona horaria y contenido del tuit. Sobre esta información, se extrajeron bigramas para todos los términos adyacentes (a excepción del campo de zona horaria). Además, también se almacenó la información geográfica adjunta al tuit para poder realizar los experimentos y el entrenamiento del modelo.

[NOTE]
.Twitter Streaming API
====
Conjunto de APIs ofrecidas por Twitter que permiten acceder al streaming real de tuits que gestiona la aplicación. Se ofrecen 3 tipos de streaming en función del contenido que se desee analizar:

[cols="2,4"]
|===
|*Stream público*
|Ofrece un 1% del total de tuits públicos gestionados por la aplicación. Se suele utilizar principalmente para tareas de _data mining_ donde no se requiere establecer ningún filtro en concreto en base a ningún usuario.

|*Stream de usuarios*
|Permite obtener información en tiempo real acerca de los eventos recibidos por un único usuario de Twitter.

|*Stream de _Sites_*
|Ofrece la capacidad de obtener información en tiempo real de los eventos recibidos por un conjunto de usuarios. Está pensado para aplicación web o móviles que requieren monitorizar la actividad en Twitter de un conjunto de sus usuarios.
|===

La página web de documentación en Twitter acerca de las APIs de Streaming contiene una mayor información acerca de sus capacidades y la manera de interactuar con ellas: https://dev.twitter.com/docs/api/streaming
====

Una vez con toda esta información almacenada, se utilizó una técnica de estimación denominada «gaussian mixture models» en donde cada bigrama que aparezca más de un mínimo número de veces se asocia a las coordenadas del tuit que lo contiene. Cada asociación va vinculada a un peso específico en función del bigrama y la suma de todos los pesos relativos a un mismo tuit resulta en la probabilidad total de que pertenezca a dichas coordenadas.

[NOTE]
.Gaussian mixture models
====
Un modelo Gaussiano mixto es un modelo probabilístico que asume que todos sus datos fueron generados a partir de la unión de un número finito de distribuciones Gaussianas con parámetros desconocidos.

— http://scikit-learn.org/stable/modules/mixture.html
====

Para calcular el peso total de un tuit a partir del peso de cada bigrama, el equipo de Reid Priedhorsky desarrolló tres métodos diferentes:

Peso por propiedades de calidad:: Se realiza la suma de todos los pesos asignados para cada bigrama y se utiliza su total como el total del tuit.

Peso por error inverso:: Se calcula el error de cada bigrama utilizando el conjunto de datos de entrenamiento y se realiza la suma de todos los errores obtenidos. Después, se aplica el inverso sobre el error total, para obtener un valor que implique que cuanto mayor sea el error, menor sea el peso del tuit.

Peso por optimización:: Aprovechando los dos casos anteriores, se plantea una nueva característica que pueda aportar el peso a cada bigrama utilizando la información que pueden dar tanto sus propiedades de calidad como su valor de error sobre el error total. De esta manera, se calcularía un nuevo valor para cada bigrama que, en conjunto con el del resto de bigramas que componen el tuit, resultaría en el peso total para dicho tuit.

Todos los algoritmos anteriores contienen una alta dosis de componente matemático.

[NOTE]
.N-Grama
====
En este contexto, un n-grama es una combinación de *n* palabras contenidas en un tuit. A lo largo del proyecto se hará referencia a dos tipos de n-gramas: *unigramas* (combinaciones de 1 palabra) y *bigramas* (combinaciones de 2 palabras).

Un ejemplo de la extracción de bigramas sobre el contenido de un tuit sería:

«Obviamente todo esto se hace para acabar con la costumbre de nuestra infancia de los álbumes de cromos.»

Que se traduciría a:

----
Obviamente todo, todo esto, esto se, se hace,
hace para, para acabar, acabar con, con la,
la costumbre, costumbre de, de nuestra, nuestra infancia,
infancia de, de los, los álbumes, álbumes de, de cromos
----
====

Los resultados del estudio revelaron un precisión del 83% para aquellos tuits que contenían bigramas con contenido explícitamente localizable (nombres de lugares) frente a un 57% de precisión sobre tuits sin información geográfica.

===== You Are Where You Tweet: A Content-Based Approach to Geo-locating Twitter Users
_Por Zhiyuan Cheng et al. Texas A&M University_

En este estudio, Zhiyuan Cheng y su equipo aportan datos interesantes en la investigación de la geolocalización en Twitter. Centrados en buscar un algoritmo capaz de inferir la localización de un usuario *únicamente* con el contenido de sus tuits, establecen tres criterios que serán ampliamente utilizados por el resto de investigaciones posteriores:

1. Se deben buscar términos con un fuerte componente discriminativo mediante la aplicación de algoritmos que sirvan para normalizar la frecuencia de apariciones de un término.

2. El test Likelihood Ratio es capaz de obtener puntuaciones bastante acertadas para este dominio específico.

3. Los términos más altamente discriminativos se caracterizan por una alta frecuencia y una baja dispersión.

[NOTE]
.Likelihood Ratio test
====
El test Likelihood-Ratio es un método estadístico ampliamente utilizado en problemas donde se pretenden comparar dos conjuntos de datos a través de una serie de supuestos. En <<_log_likelihood_ratio_test>> se exponen de manera detallada sus principales características y su aplicación en el proyecto actual.
====

Entre los resultados que presentaron, afirman ser capaces de localizar correctamente el 51% de los tuits dentro de un radio de error de 100 millas (~= 161 km.).

===== Otros artículos de interés

Los artículos anteriores han sido seleccionados como los más representativos de las principales vías de investigación para inferir la localización de un usuario en redes sociales en base al contenido de sus publicaciones. A continuación, se enumeran otros artículos de interés que pueden ayudar a conocer vías alternativas sobre las investigaciones propuestas así como nuevos resultados.

* *Location Type Classification Using Tweet Content* _por Haibin Liu et al. The Pennsylvania State University_
* *TweetLocalize: Inferring Author Location in Social Media* _por Evan Sparks et al. University of California-Berkeley_
* *Inferring the Location of Twitter Messages Based on User Relationships* _por Clodoveu A. Davis Jr. et al. Universidade Federal de Minas Gerais_
* *Geolocation Prediction in Social Media Data by Finding Location Indicative Words* _por HAN Bo et al. University of Melbourne_
* *Home Location Identification of Twitter Users* _por Jalal Mahmud et al. IBM Research_
* *Geotagging One Hundred Million Twitter Accounts with Total Variation Minimization* _por Ryan Compton et al. HRL Laboratories (Malibu)_
