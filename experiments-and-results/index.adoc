== Experimentos y resultados

Para comprobar la validez de los algoritmos anteriores se plantearon una serie de experimentos que trabajasen sobre conjuntos de tuits escritos tanto en inglés como en español, con el objetivo de poder obtener resultados positivos a nivel de país, provincia, área metropolitana y barrio.

La selección de los idiomas inglés y español como base para los experimentos se realizó a tenor de ser los dos lenguajes, a priori, más complejos de analizar debido a que son hablados en muchas partes del mundo. Por ejemplo, haber escogido como idioma el italiano, haría que las posibilidades de geolocalización se viesen reducidas prácticamente a Italia; ídem en el caso de haber utilizado alemán, que tan sólo es hablado en Alemania, Austria, Suiza y parte de Luxemburgo.

=== Primeros experimentos: trabajando con grandes volúmenes de datos

Los primeros experimentos se basaron en establecer diferencias a nivel de país. Para ello, se realizó un proceso de recolección de tuits durante una semana para los siguientes casos:

. Tuits de España escritos en español
. Tuits del mundo escritos en español
. Tuits del Reino Unido escritos en inglés
. Tuits del mundo escritos en inglés

En total esta fase duró 4 semanas, recolectando en torno a `2 x 8GB` de datos para los tuits globales, así como `2 x 1GB` para los tuits localizados en España y el Reino Unido.

Estos primeros conjuntos de datos permitieron que se desarrollasen los algoritmos de puntuación LLR y se empezase a comprobar empíricamente qué resultados aportaban los términos utilizados (menciones, hashtags, bigramas) así como investigar que otros campos o términos del perfil del usuario podrían ayudar a encontrar pistas acerca de su geolocalización. Durante esta fase se añadió el uso de _keywords_ tanto a nivel de contenido de un tuit como sobre el campo de localización del usuario, sospechando que podrían aportar más información útil en base a los resultados LLR que se estaban observando a nivel de bigramas.

Sobre estos conjuntos de datos no llegaron a establecerse pruebas que involucrasen software de aprendizaje automático, puesto que el uso de grandes volúmenes de datos quedó descartado al comprobar empíricamente que los términos que implican contenido geolocalizable no tienen que ser uniformes en el tiempo para una determinada región. Esta apreciación se realizó al trabajar con nuevos conjuntos de datos más pequeños, donde aparecieron como términos muy significativos aquellos que tenían que ver con un evento temporal muy concreto, el fallecimiento del seleccionador de fútbol nacional, Luis Aragonés.

.Puntuación LLR para algunos términos recogidos en conjuntos de datos entre el 1 y 2 de febrero de 2014
----
48.958529065415576  aragonés gran
49.17093149031471   aragonés selección
50.049053227619474  aragonés descanse
50.049053227619474  grandes luis
50.739417608310795  luis roja
50.97596629207029   luis nunca
50.97596629207029   luis mas
51.215854517258855  aragones hoy
51.215854517258855  aragonés historia
51.45916160893309   fútbol hombre
51.95636312422304   aragonés hombre
52.21042998468123   siempre aragones
52.46826083659376   luis mejor
52.46826083659376   dep sabio
56.28098057747021   descanse paz
81.59614077426396   fútbol grande
102.31617863438613  entrenador gran
107.56036254304512  bernabéu santiago
107.5697695101089   noticia triste
107.87375147152346  hoy madrid
111.68234684538564  hizo hombre
111.93538868096397  dep triste
115.39967536884996  fútbol va
116.50155357908382  futbol hoy
119.45187311362997  día fútbol
----

Como se puede observar, términos vinculados al fallecimiento del seleccionador aportaban una gran información geográfica que hacía que todos los tuits que los contenían prácticamente fuesen vinculados a España (lo cual en este caso sería correcto). Pero, ¿qué sucede si ocurre sobre un evento que se pueda aplicar sobre cualquier otro lugar del mundo en cualquier momento?

Por ejemplo, es habitual que durante los meses de verano en el hemisferio sur, términos relativos a la estación estival sean más habituales en países como Argentina, Chile, etc. que en España. Lo cual sería justamente al revés en épocas de verano en el hemisferio norte. Por tanto, es importante tener en cuenta que los términos y el vocabulario tienen una importancia temporal, y el hecho de obtener grandes volúmenes de datos no tiene porque beneficiar el entrenamiento de un modelo de aprendizaje automático para inferir la localización de un tuit.

Por ello, se optó por trabajar siempre con conjuntos de datos recogidos en periodos de 24 horas, para evaluarlos contra colecciones de tuits que se recogerían en las 24 horas siguientes. De esta manera se puede aprovechar la repercusión de ciertos términos ante cualquier evento.

=== Trabajando con diferentes niveles de granularidad

==== Conceptos previos

===== Precisión y exhaustividad

Para entender los siguientes resultados, será necesario explicar dos conceptos clave que se repetirán a lo largo de las diferentes tablas resumen. El concepto de *precisión* se puede entender como el número de predicciones que coinciden con los resultados reales sobre el total de las predicciones realizadas.

Por tanto, si tenemos un total de 20 predicciones y 18 de las mismas han coincidido con su valor real, se consideraría que el porcentaje de precisión sería:

----
(18/20) * 100 = 90% de precisión
----

El concepto *exhaustividad* se explica como el porcentaje de tuits locales que se han identificado sobre el conjunto de tuits locales reales. En este caso, partiendo de un ejemplo en el que se hubiesen etiquetado 25 tuits como locales de manera correcta y sabiendo que en el conjunto a evaluar existían 30 tuits locales, el porcentaje de exhaustividad de nuestro modelo sería de:

----
(25/30) * 100 = 83.33%
----

Entendiendo este porcentaje como que para cada 100 tuits que sabemos son locales, nuestro modelo es capaz de detectar ~ 83 satisfactoriamente.

===== Umbral de precisión

Una característica que permite manejar el grado de exhaustividad de cada modelo es el valor que se determine como *umbral de precisión*.

Por defecto, Vowpal Wabbit devuelve un valor entre 0 y 1 con la probabilidad de que ese ejemplo pertenezca al conjunto de tuits locales o no (entendiendo 1 como que *sí* pertenece al conjunto local y 0 como que *no*).  Por tanto, es habitual que muchos valores que son realmente 1, no aparezca en los resultados de la predicción de manera tan absoluta, si no que se muestren con valores cada vez más cercanos a 1 en función del grado de confianza del clasificador en su predicción: _0.5, 0.6, 0.7, etc._

Ese valor que determinemos como umbral permitirá que más o menos valores sean etiquetados por el clasificador como locales y, por tanto, que más o menos tuits locales puedan ser potencialmente etiquetados. Sin embargo, cuanto más bajo pongamos el umbral de precisión, más baja será la precisión y por tanto se encontrará más ruido en los resultados finales.

Para los siguientes ejemplos se ha tomado como umbral el valor *0.5*, el cual demuestra tener, de manera empírica, un buen comportamiento en la relación precisión - exhaustividad.

include::country.adoc[]

include::province.adoc[]

include::metropolitan_area.adoc[]

include::neighbourhood.adoc[]
