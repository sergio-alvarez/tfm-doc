<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE book PUBLIC "-//OASIS//DTD DocBook XML V4.5//EN" "http://www.oasis-open.org/docbook/xml/4.5/docbookx.dtd">
<?asciidoc-toc?>
<?asciidoc-numbered?>
<book xmlns="http://docbook.org/ns/docbook" lang="es">
<bookinfo>
<title>Geolocalización de usuarios en medios sociales mediante análisis de contenidos</title>
<date>2014-04-01</date>
<author>
<firstname>Sergio</firstname>
<othername>Álvarez</othername>
<surname>Suárez</surname>
<email>UO204823@uniovi.es</email>
</author>

<authorinitials>SÁS</authorinitials>



</bookinfo>
<chapter id="_introducci_n">
<title>Introducción</title>
<section id="_motivaci_n_del_proyecto">
<title>Motivación del proyecto</title>
<simpara>Aquí la motivación del proyecto</simpara>
</section>
<section id="_alcance">
<title>Alcance</title>
<simpara>Aquí el alcance del proyecto.</simpara>
</section>
<section id="_estado_del_arte">
<title>Estado del arte</title>
<simpara>El crecimiento exponencial de las redes sociales durante los últimos años ha despertado un gran interés en los diferentes ámbitos de la informática, siendo un claro objetivo comercial para profesionales del sector, así como un nuevo campo de investigación para los investigadores universitarios.</simpara>
<simpara>Como consecuencia de todo ello, durante los últimos años han ido apareciendo diversas aplicaciones que, de una u otra manera, se centran en estudiar ciertos aspectos de las redes sociales para poder extraer información acerca de sus usuarios gracias a las diversas publicaciones que estos mismos realizan en sus perfiles.</simpara>
<simpara>El estudio de la geolocalización de un usuario a partir de su contenido, sin embargo, es una de las pocas áreas que <emphasis>tan sólo</emphasis> agrupa un pequeño número de estudios teóricos, pero en donde no han proliferado herramientas que comprueben de manera empírica los resultados teóricos emitidos por diversos investigadores.</simpara>
<simpara>Por ello, en este capítulo se recopilan algunos <emphasis>papers</emphasis> que han servido como punto de arranque para este proyecto, así como algunas aplicaciones que comparten características similares.</simpara>
<section id="_papers">
<title>Papers</title>
<simpara>Estos son los <emphasis>papers</emphasis> más importantes y que han tenido una mayor transcendencia a la hora de desarrollar el proyecto.</simpara>
<section id="_tweets_from_justin_bieber_s_heart_the_dynamics_of_the_location_field_in_user_profiles">
<title>Tweets from Justin Bieber’s Heart: The Dynamics of the "Location" Field in User Profiles</title>
<simpara><emphasis>Por Brent Hecht et al. Northwestern University y Palo Alto Research Center</emphasis></simpara>
<simpara>El estudio liderado por Brent Hecht demuestra como aproximadamente el 66% de los usuarios no utiliza el campo de <emphasis>Localización</emphasis> en sus perfiles para informar acerca de su localización real. Por tanto, propone como estrategia el conteo de los términos que forman cada tuit con el objetivo de poder realizar cálculos estadísticos que permitan identificar aquellas palabras más indicativas para cada localización.</simpara>
<simpara>Esta estrategia será parcialmente utilizada en la implementación del presente proyecto.</simpara>
</section>
<section id="_where_is_this_tweet_from_inferring_home_locations_of_twitter_users">
<title>Where Is This Tweet From? Inferring Home Locations of Twitter Users</title>
<simpara><emphasis>Por Jalal Mahmud et al. IBM Research</emphasis></simpara>
<simpara>Con el objetivo de poder identificar un tuit a nivel de ciudad, este estudio plantea la posibilidad de analizar tres tipos de términos diferentes para localizar una publicación en Twitter:</simpara>
<orderedlist numeration="arabic">
<listitem>
<simpara>Palabras</simpara>
</listitem>
<listitem>
<simpara>Hashtags</simpara>
</listitem>
<listitem>
<simpara>Nombres de lugares (utilizando un <emphasis>gazetteer</emphasis> <footnote><simpara>Conjunto de nombres geográficos que, junto con un mapa, constituye una importante referencia sobre lugares y sus nombres</simpara></footnote> geográfico)</simpara>
</listitem>
</orderedlist>

<simpara>Es interesante observar como empiezan a aparecer pequeñas diferencias entre términos, considerando que en función de su categoría, pueden ofrecer más o menos información geográfica. Esta misma estrategia será también utilizada en el presente proyecto, mediante la extracción de Hashtags, Menciones y N-gramas.</simpara>
<simpara>También en este estudio se hace mención a la utilización de un <emphasis role="strong">software de aprendizaje automático</emphasis>, en este caso WEKA, y su conjunción con un modelo estadístico que realice los cálculos necesarios para el clasificador. El modelo que seleccionaron de manera empírica fue <emphasis>Naïve Bayes Multimonial</emphasis>.</simpara>
</section>
<section id="_tweolocator_a_non_intrusive_geographical_locator_system_for_twitter">
<title>TweoLocator: A Non-Intrusive Geographical Locator System for Twitter</title>
<simpara><emphasis>Por Yi-Shin Chen et al. National Tsing Hua University</emphasis></simpara>
<simpara>En este estudio, Yi-Shin Chen propone un sistema denominado <emphasis role="strong">TweoLocator</emphasis> que funciona como un <emphasis>framework</emphasis> el cual, a través de diferentes etapas, asegura ofrecer unos resultados altamente fiables acerca de la localización de un usuario en Twitter.</simpara>
<simpara>Este paper ofrece el interesante concepto de n-gramas, que será utilizado en el presente proyecto como una de las estrategias para la detección de términos con posibilidad de ofrecer contenido geolocalizable.</simpara>
</section>
<section id="_a_multi_indicator_approach_for_geolocalization_of_tweets">
<title>A Multi-Indicator Approach for Geolocalization of Tweets</title>
<simpara><emphasis>Por Axel Schulz et al. SAP Research</emphasis></simpara>
<simpara>Presenta un sistema muy interesante mediante la utilización de formas poligonales en 3D para decidir la localización de un tuit y usuario. Cada polígono tiene dos valores de calidad en base al indicador que los define. Los polígonos se superponen, y la intersección de mayor altura es el área con más probabilidades de contener el tuit analizado.</simpara>
<simpara>Para obtener la información de cada tuit, utiliza varios sistemas como la <emphasis role="strong">DBPedia</emphasis> (<ulink url="http://dbpedia.org/">http://dbpedia.org/</ulink>) o <emphasis role="strong">Foursquare</emphasis> (<ulink url="https://es.foursquare.com/">https://es.foursquare.com/</ulink>) para reconocer entidades y topónimos. Su dependencia de sistemas externos impide que sea capaz de deducir una localización a través del contexto si esta no contiene ninguna referencia a una entidad localizable.</simpara>
</section>
<section id="_inferring_the_origin_locations_of_tweets_with_quantitative_confidence">
<title>Inferring the Origin Locations of Tweets with Quantitative Confidence</title>
<simpara><emphasis>Por Reid Priedhorsky et al. Los Alamos National Laboratory y Northeastern Illinois University</emphasis></simpara>
<simpara>Este nuevo estudio presenta otra estrategia para encontrar términos fuertemente localizados en base al uso de <emphasis>n-gramas</emphasis>. Para ello, los investigadores se centraron en extraer bigramas de los siguientes campos:</simpara>
<itemizedlist>
<listitem>
<simpara>Campo de Localización</simpara>
</listitem>
<listitem>
<simpara>Contenido del tuit</simpara>
</listitem>
<listitem>
<simpara>Zona horaria</simpara>
</listitem>
<listitem>
<simpara>Idioma seleccionado en el perfil del usuario</simpara>
</listitem>
</itemizedlist>

<simpara>A su vez, desarrollaron un modelo estadístico propio, basado en un clasificador Gaussiano, el cual aplicaban sobre aquellos bigramas que superaban un número mínimo de apariciones.</simpara>
</section>
<section id="_home_location_identification_of_twitter_users">
<title>Home Location Identification of Twitter Users</title>
<simpara><emphasis>Por Jalal Mahmud et al. IBM Research</emphasis></simpara>
</section>
<section id="_otros_emphasis_papers_emphasis_de_inter_s">
<title>Otros <emphasis>papers</emphasis> de interés</title>
<itemizedlist>
<listitem>
<simpara><emphasis role="strong">You Are Where You Tweet: A Content-Based Approach to Geo-locating Twitter Users</emphasis> <emphasis>por Zhiyuan Cheng et al. Texas A&amp;M University</emphasis></simpara>
</listitem>
<listitem>
<simpara><emphasis role="strong">Location Type Classification Using Tweet Content</emphasis> <emphasis>por Haibin Liu et al. The Pennsylvania State University</emphasis></simpara>
</listitem>
<listitem>
<simpara><emphasis role="strong">TweetLocalize: Inferring Author Location in Social Media</emphasis> <emphasis>por Evan Sparks et al. University of California-Berkeley</emphasis></simpara>
</listitem>
<listitem>
<simpara><emphasis role="strong">Inferring the Location of Twitter Messages Based on User Relationships</emphasis> <emphasis>por Clodoveu A. Davis Jr. et al. Universidade Federal de Minas Gerais</emphasis></simpara>
</listitem>
<listitem>
<simpara><emphasis role="strong">Geolocation Prediction in Social Media Data by Finding Location Indicative Words</emphasis> <emphasis>por HAN Bo et al. University of Melbourne</emphasis></simpara>
</listitem>
</itemizedlist>

</section>
</section>
<section id="_aplicaciones_web">
<title>Aplicaciones web</title>
<simpara>A continuación, se recopilan algunas aplicaciones con características similares a las del presente proyecto, y otras que, sin centrarse en el estudio de la geolocalización del contenido de manera específica, utilizan <emphasis role="strong">Twitter</emphasis> como fuente de información y realizan un estudio a gran escala sobre las publicaciones realizadas.</simpara>
<section id="_trendsmap">
<title>Trendsmap</title>
<simpara><emphasis role="strong">Trendsmap</emphasis> (<ulink url="http://trendsmap.com/">http://trendsmap.com/</ulink>) es una aplicación web que muestra en tiempo real las tendencias en Twitter para cada localización a escala mundial. Según datos ofrecidos por la propia web en su página de <emphasis>FAQ</emphasis>, gestionan un volumen de tuits del orden de <emphasis role="strong">80 millones al día</emphasis>.</simpara>
<simpara>Su objetivo principal consiste, por tanto, en localizar las tendencias específicas de cada localización, sin ofrecer ninguna información acerca de las posibilidades de que uno u otro tuit que contengan dicha tendencia puedan pertenecer a una localización en concreto.</simpara>
<simpara>No se ha podido encontrar ninguna información acerca del tipo de algoritmo que utiliza Trendsmap para determinar la localización de un tuit (en pos de poder determinar la tendencia para un alto número de los mismos).</simpara>
</section>
<section id="_what_the_trend">
<title>What the Trend</title>
<simpara><emphasis role="strong">What the Trend</emphasis> (<ulink url="http://whatthetrend.com/faq">http://whatthetrend.com/faq</ulink>) se centra en ofrecer al usuario una explicación acerca de los propios <emphasis>Trending Topics</emphasis> identificados por Twitter para cada localidad.</simpara>
<simpara>En este caso, la aplicación no incluye ningún tipo de algoritmo para adivinar la localidad de un volumen de tuits, si no que únicamente recoge las tendencias previamente analizadas y localizadas por Twitter.</simpara>
</section>
<section id="_klout">
<title>Klout</title>
<simpara><emphasis role="strong">Klout</emphasis> (<ulink url="http://klout.com/home">http://klout.com/home</ulink>) se describe como un servicio capaz de obtener la influencia de un usuario en la red a través de sus publicaciones y relaciones en redes sociales. Durante sus primeros años fue objetivo de varias inversiones millonarias que sacaron a la luz la gran importancia que tiene a nivel empresaria el análisis de los grandes volúmenes de información que se generan a diario en las redes sociales por parte de los propios usuarios.</simpara>
</section>
</section>
</section>
<section id="_aspectos_te_ricos">
<title>Aspectos teóricos</title>
<simpara>Aquí los aspectos teóricos.</simpara>
</section>
</chapter>
<chapter id="_planificaci_n_y_gesti_n_del_proyecto">
<title>Planificación y gestión del proyecto</title>

</chapter>
<chapter id="_an_lisis_del_sistema">
<title>Análisis del sistema</title>

</chapter>
<chapter id="_desarrollo_e_implementaci_n_del_sistema">
<title>Desarrollo e implementación del sistema</title>
<section id="_obtenci_n_de_datos">
<title>Obtención de datos</title>
<simpara>El primer paso en el desarrollo del proyecto, fue la creación de un sistema capaz de recolectar tuits con el objetivo de obtener material de entrenamiento sobre el que aplicar las diferentes estrategias planteadas.</simpara>
<simpara>Este sistema debía ser parametrizable, con el objetivo de poder configurar en cada ejecución el tipo de tuits que se querían obtener. En base a estos requisitos, se utilizó la <emphasis role="strong">API Streaming de Twitter</emphasis> (<ulink url="https://dev.twitter.com/docs/api/streaming">https://dev.twitter.com/docs/api/streaming</ulink>), la cual aporta dos características principales:</simpara>
<itemizedlist>
<listitem>
<simpara>Capacidad de obtener datos en tiempo real de Twitter de manera ininterrumpida</simpara>
</listitem>
<listitem>
<simpara>Capacidad de establecer filtros sobre el flujo de entrada:</simpara>
<itemizedlist>
<listitem>
<simpara>Filtro por idioma del tuit</simpara>
</listitem>
<listitem>
<simpara>Filtro por localización del tuit (mediante el uso de <emphasis>bounding boxes</emphasis>)</simpara>
</listitem>
</itemizedlist>

</listitem>
</itemizedlist>

<simpara>Para realizar la conexión entre el sistema desarrollado y la API de Twitter se utilizó la biblioteca <emphasis role="strong">Twitter4j</emphasis> (<ulink url="http://twitter4j.org/en/index.html">http://twitter4j.org/en/index.html</ulink>), la cual aunque originalmente está desarrollada para ser utilizada sobre Java, es perfectamente utilizable en Scala gracias a la compatibilidad entre ambos lenguajes mediante la Java Virtual Machine. La ventajas de utilizar una biblioteca construida sobre la API original de Twitter es que algunos de los problemas más habituales se solucionan a través de nuevas capas de abstracción:</simpara>
<itemizedlist>
<listitem>
<simpara>Autenticación OAuth2 simplificada mediante clases propias de la biblioteca</simpara>
</listitem>
<listitem>
<simpara>La API de Twitter4J para utilizar el Streaming de Twitter permite aislar al desarrollador de la necesidad de mantener activa la comunicación HTTP manualmente para estar conectado al Streaming de Twitter.</simpara>
</listitem>
</itemizedlist>

<figure>
<title>Modelo de comunicación entre un cliente y la API Streaming de Twitter (<ulink url="https://dev.twitter.com/docs/api/streaming">https://dev.twitter.com/docs/api/streaming</ulink>)</title>
  <mediaobject>
    <imageobject>
      <imagedata fileref="../assets/05development/twitter-streaming-api.png"/>
    </imageobject>
    <textobject><phrase>Modelo de comunicación entre un cliente y la API Streaming de Twitter</phrase></textobject>
  </mediaobject>
</figure>

<section id="_almacenamiento_de_datos">
<title>Almacenamiento de datos</title>
<simpara>Uno de los puntos más importantes que planteó el sistema para recolectar tuits era en qué formato sería más adecuado serializar los datos obtenidos.</simpara>
<simpara>En un primer momento se barajó la posibilidad de utilizar el formato CSV, el cual permitiría acceder de manera rápida al número de tuits guardados y realizar operaciones sencillas en línea de comandos mediante operaciones <literal>grep</literal>. Esta decisión fue cancelada al realizar los primeros experimentos y comprobar como el guardado de ciertos datos en formato CSV presenta muchas dificultades para poder solventar todos los casos esquina que se presentan con la aparición de contenido complejo que pueda incluir comas, comillas y otros signos de puntuación (aún en el caso de utilizar bibliotecas especializadas como OpenCSV - <ulink url="http://opencsv.sourceforge.net/">http://opencsv.sourceforge.net/</ulink> ) combinados con caracteres extraños como Emoji (<ulink url="http://www.unicode.org/faq/emoji_dingbats.html">http://www.unicode.org/faq/emoji_dingbats.html</ulink>).</simpara>
<simpara>Como consecuencia de los resultados anteriores, y apoyado en el soporte nativo ofrecido por Scala, se utilizó XML como el lenguaje de marcado que mejor podría serializar y estructurar los datos obtenidos a través de Twitter4j. El siguiente fragmento de código permite ver lo sencillo que es serializar un objeto en Scala a XML mediante la utilización de literales:</simpara>
<programlisting language="scala" linenumbering="unnumbered">class Tweet(id:String, username: String, name:String, location: String, timezone: String, createdAt:String, latitude: String,
            longitude: String, text: String) {
  def toXML =
    &lt;tweet&gt;
      &lt;id&gt;
        {id}
      &lt;/id&gt;
      &lt;username&gt;
        {username}
      &lt;/username&gt;
      &lt;name&gt;
        {name}
      &lt;/name&gt;
      &lt;location&gt;
        {location}
      &lt;/location&gt;
      &lt;timezone&gt;
        {timezone}
      &lt;/timezone&gt;
      &lt;createdAt&gt;
        {createdAt}
      &lt;/createdAt&gt;
      &lt;latitude&gt;
        {latitude}
      &lt;/latitude&gt;
      &lt;longitude&gt;
        {longitude}
      &lt;/longitude&gt;
      &lt;text&gt;
        {text}
      &lt;/text&gt;
    &lt;/tweet&gt;
}</programlisting>

</section>
<section id="_par_metros_del_sistema">
<title>Parámetros del sistema</title>
<simpara>Como parte de los requisitos del sistema, era necesario ofrecer la capacidad de parametrizar la ejecución para poder obtener un tipo de resultados u otros. A continuación se muestra un ejemplo del fichero <literal>properties</literal> que se ha utilizado para indicar al sistema algunos parámetros:</simpara>
<itemizedlist>
<listitem>
<simpara><literal>time_in</literal> y <literal>time_to_collect</literal>: permiten establecer al recolector un tiempo de ejecución representado en diferentes magnitudes.</simpara>
</listitem>
<listitem>
<simpara><literal>file_name</literal>: nombre del fichero de salida.</simpara>
</listitem>
<listitem>
<simpara><literal>coordiantes_mandatory</literal>: <literal>boolean</literal> que indica si los tuits recolectados deben contener o no información geográfica adjunta.</simpara>
</listitem>
<listitem>
<simpara><literal>filter_language</literal>: idioma en el que se desean obtener los tuits.</simpara>
</listitem>
<listitem>
<simpara><literal>stop_words_file</literal>: debido a restricciones de Twitter, es necesario proveer una lista de términos cuando se intenta realizar un filtrado por idioma. Con el objetivo de restringir lo mínimo posible el número de tuits a obtener, se provee una lista de <emphasis>stop words</emphasis> del idioma por el que se esté filtrando.</simpara>
</listitem>
<listitem>
<simpara><literal>filter_bounding_boxes_file</literal>: fichero <literal>XML</literal> que contiene los <emphasis>bounding boxes</emphasis> sobre los que se realizará el filtrado para aquellas ejecuciones que requieran tuits localizados en un área en concreto.</simpara>
</listitem>
</itemizedlist>

<note>
<simpara>El siguiente fragmento de código muestra un fichero donde se aplican a la vez todas las propiedades. En un caso real, sólo se aplicarían aquellas que tuvieran sentido para el resultado que se quisiera obtener. Por tanto, no tendría sentido que estuvieran habilitadas a la vez las propiedades <literal>filter_language</literal> y <literal>filter_bounding_boxes_file</literal></simpara>
</note>

<screen># Valid values for time_in property:
#
# DAYS
# HOURS
# MICROSECONDS
# MILLISECONDS
# MINUTES
# NANOSECONDS
# SECONDS
time_in=DAYS
time_to_collect=1

# File to save the results
file_name=ES-Spain.xml

coordinates_mandatory=true
filter_language=es
stop_words_file=spanish-stop-words.txt
filter_bounding_boxes_file=es_bounding_boxes.xml</screen>

</section>
<section id="_ejemplo_de_resultados">
<title>Ejemplo de resultados</title>
<simpara>Un ejemplo de los resultados obtenidos por el recolector sería el siguiente:</simpara>
<programlisting language="xml" linenumbering="unnumbered">&lt;tweets&gt;
  &lt;tweet&gt;
    &lt;username&gt;
      gaabriforner
    &lt;/username&gt;
    &lt;location&gt;
      Málaga
    &lt;/location&gt;
    &lt;timezone&gt;
      Athens
    &lt;/timezone&gt;
    &lt;createdAt&gt;
      2014-03-04 21:53
    &lt;/createdAt&gt;
    &lt;latitude&gt;
      -4.437747
    &lt;/latitude&gt;
    &lt;longitude&gt;
      36.7055494
    &lt;/longitude&gt;
    &lt;text&gt;
      y ante todo a echarle fuerza d voluntad y ganas para conseguir lo que quiero!!
    &lt;/text&gt;
  &lt;/tweet&gt;
&lt;/tweets&gt;</programlisting>

</section>
</section>
<section id="_an_lisis_de_datos">
<title>Análisis de datos</title>

</section>
<section id="_entrenamiento_del_modelo_de_an_lisis_de_datos">
<title>Entrenamiento del modelo de análisis de datos</title>

</section>
</chapter>
</book>