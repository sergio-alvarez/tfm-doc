=== Estado del arte

El crecimiento exponencial de las redes sociales durante los últimos años ha despertado un gran interés en los diferentes ámbitos de la informática, siendo un claro objetivo comercial para profesionales del sector, así como un nuevo campo de investigación para los investigadores universitarios.

Como consecuencia de todo ello, durante los últimos años han ido apareciendo diversas aplicaciones que, de una u otra manera, se centran en estudiar ciertos aspectos de las redes sociales para poder extraer información acerca de sus usuarios gracias a las diversas publicaciones que estos mismos realizan en sus perfiles.

El estudio de la geolocalización de un usuario a partir de su contenido, sin embargo, es una de las pocas áreas que _tan sólo_ agrupa un pequeño número de estudios teóricos, pero en donde no han proliferado herramientas que comprueben de manera empírica los resultados teóricos emitidos por diversos investigadores.

Por ello, en este capítulo se recopilan algunos estudios teóricos y artículos de investigación que han servido como punto de arranque para este proyecto, así como algunas aplicaciones que comparten características similares.

==== Estudios y artículos de investigación

===== Tweets from Justin Bieber’s Heart: The Dynamics of the "Location" Field in User Profiles
_Por Brent Hecht et al. Northwestern University y Palo Alto Research Center_

El estudio liderado por Brent Hecht demuestra de manera científica como el uso del campo de Localización disponible en los perfiles de los usuarios en Twitter no es un indicador válido para obtener su posición geográfica real.

Entre los datos obtenidos por Brent y su equipo se pueden destacar los siguientes:

. Sólo un 66% de los usuarios utiliza el campo de Localización para aportar información geográfica válida (es decir, localizaciones reales pero que *no tienen porqué indicar su situación real*. Por ejemplo, si una persona de *Oviedo* escribe *California* en el campo de Localización de su perfil, este estudio lo incluye dentro del 66% anterior).

. Algunos de los usos que los usuarios dentro del 34% restante aplican al campo de Localización se puede observar en <<location-use-type>>.

. La manera de distinguir entre localización real y ficticia supuso de un proceso manual en el que dos miembros del equipo debieron revisar tuit a tuit el campo de Localización, debido a la habilidad de los usuarios para poder expresar sarcasmo o ironía, así como expresiones comunes que pueden tener asociado un componente geográfico inherente (un ejemplo puede ser referirse al Principado de Asturias como _la tierrina_).

.Tipos de uso del campo de Localización por parte de los usuarios de Twitter
[cols="3,1", id="location-use-type"]
|===
|Cultura popular
|12.9%

|Referencias a su propia privacidad
|1.2%

|Insultos o contenido violento
|4.6%

|Localizaciones no terráqueas
|5.0%

|Emociones negativas hacia su localización real
|3.2%

|Naturaleza sexual
|3.2%
|===

Como alternativa a los resultados anteriores, y buscando una manera de automatizar el proceso y encontrar resultados más fiables y exhaustivos, se propusieron hacer un primer experimento para comprobar si el estudio de los contenidos publicados por un usuario pueden aportar la información necesaria para permitir inferir su ubicación geográfica.

Para ello, utilizaron un software de aprendizaje automático y un clasificador Bayesiano multinomial que en base a un conjunto de datos obtenidos a partir de aplicar el algoritmo _CALGARI_ (de implementación propia), fuese capaz de predecir a qué área (País y Estado) pertenece un tuit en base a su contenido.

[NOTE]
.CALGARI
====
El algoritmo CALGARI tiene como objetivo normalizar la frecuencia con la que un término ha aparecido dentro de un dataset de tuits para priorizar aquellos que son más específicas de un área (ciudad o estado) en concreto, penalizando palabras comunes como _ya, hola, adiós, etc._
====

Entre los resultados ofrecidos por el estudio destacan un *72.7% de acierto para inferir el país* de un usuario pero tan *sólo un 30% de acierto a nivel de estado*.

Como apunte adicional, es interesante una afirmación que se enuncia en el artículo cuando se hace referencia al nuevo campo de localización que la API Streaming de Twitter ofrece para adjuntar información geolocalizada (siempre que el usuario lo permita):

____
First, our focus is on the geographic information revealed in the “location” field of user profiles, a type of geographic information that is prevalent across the Web 2.0 world. *Second, we found that only 0.77% of our 62 million tweets contained this embedded location information*.
____

De 62 millones de tuits, únicamente un 0.77% (~= 477.400) contenían información geográfica adjunta.

===== Where Is This Tweet From? Inferring Home Locations of Twitter Users
_Por Jalal Mahmud et al. IBM Research_

Con el objetivo de poder identificar un tuit a diferentes granularidades: ciudad o estado, el estudio plantea la posibilidad de analizar tres tipos de términos diferentes para localizar una publicación en Twitter:

. Palabras
. Hashtags
. Nombres de lugares (utilizando un gazetteerfootnote:[Conjunto de nombres geográficos que, junto con un mapa, constituye una importante referencia sobre lugares y sus nombres] geográfico). Puesto que estos términos podía estar compuestos por más de una palabra, se utilizaron bigramas y trigamas, así como un heurístico especializado en reconocer nombres de lugares expresados mediante vocabulario común (un ejemplo sería _Red Sox_ para referirse a la ciudad de Boston).

Es interesante observar como empiezan a aparecer pequeñas diferencias entre términos, considerando que en función de su categoría, pueden ofrecer más o menos información geográfica. Esta misma estrategia será también utilizada en el presente proyecto, mediante la extracción de Hashtags, Menciones y N-gramas.

Con el objetivo de minimizar la aparición de ruido, normalizaron el contenido de cada tuit eliminando signos de puntuación (a excepción de aquellos que indican una entidad propia cuando se encuentran al principio de una palabra, como `#` para indicar _hashtags_) y palabras vacías.

También en este estudio se hace mención a la utilización de un *software de aprendizaje automático*, en este caso WEKA, y su conjunción con un modelo estadístico que realice los cálculos necesarios para el clasificador. El modelo que seleccionaron de manera empírica fue un clasificador Bayesiano multinomial.

La estrategia propuesta en este trabajo para inferir la localización de un usuario en Twitter fue:

. A lo largo de sus tuits, mencionará más veces su ciudad o estado de origen que el resto de ciudades o estados.
. Visitará más lugares de su ciudad o estado de origen que del resto de ciudades o estados (para detectar este tipo de visitas, se guardan todas las URLs generadas a partir de _check-ins_ compartidos a través de *Foursquare* para luego comprobar su información asociada a través de la propia API de Foursquare).

A partir de estas premisas y de las decisiones anteriores, se crearon 3 modelos diferentes para poder entrenar sobre cada uno de los términos que se quieren extraer: palabras, hashtags y nombres de lugares. Los resultados presentados a nivel de ciudad no fueron realmente positivos, y sólo presentan niveles de precisión superiores al 70% cuando se permiten márgenes de error superiores a 200 millas (~= 322 kilómetros).

Por último, no se especifica con exactitud cómo actúa realmente el algoritmo cuando se trabaja con usuarios que no tienen contenido generado por Foursquare o no hacen una referencia explícita a su ciudad, estado o país.

===== TweoLocator: A Non-Intrusive Geographical Locator System for Twitter
_Por Yi-Shin Chen et al. National Tsing Hua University_

En este estudio, Yi-Shin Chen diseña un sistema que a través de diferentes etapas y aglutinando varios procesos es capaz de inferir la localización de un usuario en Twitter en función del contenido de sus tuits.

Baseline Classification::

A partir de un gran dataset de usuarios de Twitter, en esta fase se realiza un análisis para comprobar qué perfiles puede ser potencialmente válidos para realizar un análisis de contenidos, eliminando aquellos que puedan pertenecer a _bots_ automáticos o sean perfiles de spam. Una vez se obtiene una masa de usuarios válidos se procede, dentro aún de esta etapa, a analizar todos sus tuits (a excepción de aquellos con información de geolocalización asociada) para volver a categorizarlos en 3 tipos:
* *Direct subject*: Tuits que hacen referencia al usuario en primera persona.
* *Anonymous subject*: Tuits que no hacen una referencia directa al usuario, pero utilizan otros pronombres personales o la primera secuencia de palabras es un verbo que no es una palabra vacía.
* *Others*: Tuits descartados por no pertenecer a ninguna de las 2 categorías anteriores.

Rule Generation::

Una vez todos los tuits anteriores han sido analizados semánticamente se realiza una normalización de los mismos aplicando técnicas de análisis de texto (utilizando un tokenizador y un stemmer) para luego poder formar n-gramas como los mismos. Durante esta etapa, se intentan inferir reglas que permitan asociar términos comunes a localizaciones específicas como aeropuertos, parques, estaciones de tren, etc.

Location Discovery::

A partir de los términos de cada tuit, se generan trigramas, bigramas y unigramas y se comparan sobre un gazetteer y las reglas generadas en el paso anterior, obteniendo localizaciones que se pueden agrupar en:

* *Explicit Specific*: Nombres que hacen una referencia directa a una ciudad o lugar determinado, como por ejemplo «The White House» or «Los Angeles».
* *Explicit*: Nombres que hacen referencia a localizaciones generales como parques o gimnasios.
* *Implicit*: Combinaciones de palabras que implícitamente sugieren una localización. Estos resultaos se obtienen a partir de las reglas generadas en el paso anterior.

Toponym Removal:: Mediante la utilización de un clúster, y partiendo de la premisa de que un usuario nombrará con mayor frecuencia lugares cercanos a su lugar de origen, en esta fase se analizan las menciones realizadas por el usuario sobre ciudades, lugares, países y se refinarán los datos para obtener su lugar de origen.

Timeline Sorting::

Es el último paso en el refinamiento de los datos. En esta fase se intenta minimizar la aparición de ruido detectando aquellas ocasiones en las que el usuario hace referencia a una localización geográfica sin aportar una información real acerca de su posición. Por ejemplo, es habitual que alguien situado en Asturias pueda nombrar la ciudad de Nueva York para hablar de alguna noticia o para mostrar sus ganas por conocer la ciudad, sin que esa mención indique que se encuentre realmente allí. Para resolver este problema, y aceptando que en algunos casos sólo se podrían resolver dichas inconsistencias de manera manual mediante la intervención humana, se diseñó un sistema que a partir de dos tuits con contenido geolocalizado consecutivos (del mismo usuario) compruebe si su diferencia en el tiempo es acorde a la posibilidad de haberse movido entre ambos puntos a una velocidad normal de transporte.

Location Inferred::

De acuerdo a los resultados obtenidos en todas las fases anteriores y de acuerdo al nivel sobre que el que se haya podido inferir su localización, los usuarios son clasificados en los siguientes grupos:

* *No information*: Si no se ha podido obtener información geográfica válida para inferir la localización del usuario.
* *Just country*: Si sólo se ha podido inferir el país del usuario.
* *Timeline*: Se han podido detectar ubicaciones actuales y previas del usuario, pero no su lugar de origen.
* *Hometown*: Se han podido detectar ubincaciones actuales y previas del usuario y *también* su lugar de origen. Es el grupo con información más completa.

En las conclusiones que se exponen en el artículo se muestran unos resultados bastante aceptables, donde hay porcentajes de acierto cercanos al 80%. Al igual que en el caso anterior, TweoLocator tiene una gran dependencia de que los usuarios incluyan en el contenido de sus tuits información explícitamente geolocalizable.

===== A Multi-Indicator Approach for Geolocalization of Tweets
_Por Axel Schulz et al. SAP Research_

En este artículo, un equipo de investigación de *SAP AG* presenta un enfoque muy interesante para inferir la localización de un usuario mediante la utilización de formas poligonales en 3D. Los polígonos se superponen, y la intersección de mayor altura es el área con más probabilidades de contener al usuario analizado.

La altura de cada polígono viene determinada por pesos específicos que se aplican en función de la fuente utilizada para obtener esa localización. Cada fuente tiene sus propios estándares de calidad y sus propias métricas para indicar más o menos fiabilidad.

Para obtener las coordenadas o posiciones geográficas que deben ocupar los polígonos, los investigadores extraen información de los siguientes campos:

Contenido del tuit::

Se optó por utilizar *DBPedia Spotlight* para extraer las entidades que existían en el tuit. Con los resultados de la extracción, se seleccionaban únicamente aquellas que tenían coordenadas asociadas. Además, se utilizó como calidad de cada predicción la propia confianza aportada por DBPedia Spotlight en su resultado. También se utilizaron las publicaciones realizadas a través de servicios como Foursquare, Flickr o Ubisoft, las cuales tienen adjunta información geográfica precisa mediante la utilización de coordenadas geográficas.

Localización::

Se hizo uso de gazetteers que permitiesen buscar coincidencias textuales en el campo de Localización. Además, se volvió a utilizar DBPedia Spotlight para conseguir trabajar con expresiones comunes como «La gran manzana» y expresiones regulares para detectar si algún usuario incluía coordenadas geográficas directamente en su campo de Localización.

Web del usuario::

Para aquellos usuarios que añaden en su perfil su página web personal se aplican dos estrategias:

. Extraer el dominio de la página (.com, .es, etc).
. Utilizar la dirección IP y obtener las coordenadas a través del servicio IPInfoDB.

Zona horaria::

Se asume como cierto que la zona horaria asociada al usuario es la capital de su país de origen.

Los resultados de este estudio presentan mejorías respecto a otras investigaciones basadas en inferir la localidad de un usuario mediante el uso de *múltiples indicadores* con un 37% de acierto con una distancia de error de 10km y un 48% para 25km; así como un 54% cuando el margen se amplía a 50km.

===== Inferring the Origin Locations of Tweets with Quantitative Confidence
_Por Reid Priedhorsky et al. Los Alamos National Laboratory y Northeastern Illinois University_

Este nuevo estudio presenta otra estrategia para encontrar términos fuertemente localizados en base al uso de _n-gramas_. Para ello, los investigadores se centraron en extraer bigramas de los siguientes campos:

* Campo de Localización
* Contenido del tuit
* Zona horaria
* Idioma seleccionado en el perfil del usuario

A su vez, desarrollaron un modelo estadístico propio, basado en un clasificador Gaussiano, el cual aplicaban sobre aquellos bigramas que superaban un número mínimo de apariciones.

===== Otros _papers_ de interés

* *You Are Where You Tweet: A Content-Based Approach to Geo-locating Twitter Users* _por Zhiyuan Cheng et al. Texas A&M University_
* *Location Type Classification Using Tweet Content* _por Haibin Liu et al. The Pennsylvania State University_
* *TweetLocalize: Inferring Author Location in Social Media* _por Evan Sparks et al. University of California-Berkeley_
* *Inferring the Location of Twitter Messages Based on User Relationships* _por Clodoveu A. Davis Jr. et al. Universidade Federal de Minas Gerais_
* *Geolocation Prediction in Social Media Data by Finding Location Indicative Words* _por HAN Bo et al. University of Melbourne_
* *Home Location Identification of Twitter Users* _por Jalal Mahmud et al. IBM Research_
* *Geotagging One Hundred Million Twitter Accounts with Total Variation Minimization* _por Ryan Compton et al. HRL Laboratories (Malibu)_

==== Aplicaciones web

A continuación, se recopilan algunas aplicaciones con características similares a las del presente proyecto, y otras que, sin centrarse en el estudio de la geolocalización del contenido de manera específica, utilizan *Twitter* como fuente de información y realizan un estudio a gran escala sobre las publicaciones realizadas.

===== Trendsmap
*Trendsmap* (http://trendsmap.com/) es una aplicación web que muestra en tiempo real las tendencias en Twitter para cada localización a escala mundial. Según datos ofrecidos por la propia web en su página de _FAQ_, gestionan un volumen de tuits del orden de *80 millones al día*.

Su objetivo principal consiste, por tanto, en localizar las tendencias específicas de cada localización, sin ofrecer ninguna información acerca de las posibilidades de que uno u otro tuit que contengan dicha tendencia puedan pertenecer a una localización en concreto.

No se ha podido encontrar ninguna información acerca del tipo de algoritmo que utiliza Trendsmap para determinar la localización de un tuit (en pos de poder determinar la tendencia para un alto número de los mismos).

===== What the Trend
*What the Trend* (http://whatthetrend.com/faq) se centra en ofrecer al usuario una explicación acerca de los propios _Trending Topics_ identificados por Twitter para cada localidad.

En este caso, la aplicación no incluye ningún tipo de algoritmo para adivinar la localidad de un volumen de tuits, si no que únicamente recoge las tendencias previamente analizadas y localizadas por Twitter.

===== Klout
*Klout* (http://klout.com/home) se describe como un servicio capaz de obtener la influencia de un usuario en la red a través de sus publicaciones y relaciones en redes sociales. Durante sus primeros años fue objetivo de varias inversiones millonarias que sacaron a la luz la gran importancia que tiene a nivel empresaria el análisis de los grandes volúmenes de información que se generan a diario en las redes sociales por parte de los propios usuarios.
