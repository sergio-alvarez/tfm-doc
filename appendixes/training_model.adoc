[appendix]
== Software de aprendizaje automático y Vowpal Wabbit

=== Software de aprendizaje automático

=== Vowpal Wabbit

*Vowpal Wabbit* footnote:[http://hunch.net/~vw/] es un proyecto creado originalmente por _Yahoo! Research_ que fue posteriormente continuado por _Microsoft Research_, consistente en la creación de un nuevo algoritmo de aprendizaje automático rápido y escalable que permita trabajar con grandes cantidades de datos. A partir de una serie de información específicamente preparada para ser consumida por Vowpal Wabbit, este es capaz de crear un propio modelo de datos que sirva como base de entrenamiento para después, mediante la aplicación de diversos algoritmos, predecir un resultado en base al conocimiento adquirido en ejecuciones anteriores.

Además de la velocidad y precisión de los resultados que puede ofrecer Vowpal Wabbit, una de sus características más importantes es la capacidad de funcionar como un demonio del sistema e ir aprendiendo _en caliente_ a través de nuevos modelos de datos. Esto, a diferencia de otros software de aprendizaje automático, permite que el sistema pueda adquirir un conocimiento incremental y ofrecer mejores resultados a medida que pasa el tiempo.

==== Normalización de datos

Para aprovechar toda la potencia y velocidad que ofrece Vowpal Wabbit, es necesario generar ficheros de entrada que estén estructurados de acuerdo a un formato optimizado para el clasificador. En este caso, Vowpal Wabbit espera datos de entrada estructurados de la siguiente manera:

----
[Label] [Importance [Tag]]|Namespace Features |Namespace Features ... |Namespace Features # <1>
----
<1> https://github.com/JohnLangford/vowpal_wabbit/wiki/Input-format

En el presente proyecto, esta estructura generaría datos de la siguiente manera:

----
1 |Tweet @adrianzenb scl rainer wirth óscar amigos radio quillota
0 |Tweet @thomasuribe medellín colombia celebra día hombre
1 |Tweet @fvminajx @cursiperono mujer ruega punto
----

Debido a que un primer momento se consideró la opción de trabajar con modelos multiclase, el sistema que realiza la traducción entre los ficheros de puntuación generados por el sistema Puma y los datos que espera recibir Vowpal Wabbit, debía de ser parametrizable para poder cubrir los siguientes dos casos:

1. Entrenar un modelo de clasificación binario donde sólo se indicara si un tuit pertenece o no a un conjunto de coordenadas (útil para modelos en los que se quiera conocer de manera binaria si una dato pertenece o no a una localización en concreto).
2. Entrenar un modelo de clasificación multiclase donde se agruparan las clases en torno a un número de decimales para la latitud y longitud. Esto haría que se considerasen de la misma clase todos los tuits cuyas coordenadas con 3 decimales sean las mismas, permitiendo obtener predicciones con un grado de precisión de 10 kilómetros (en caso de agrupar por 2 decimales, la precisión sería de 100 y con 1, de 1000 kilómetros).

Para ello, se creo un sistema que mediante una interfaz de línea de comandos pudiese ser configurable mediante los siguientes argumentos:

----
vw-input-translator 1.0
Usage: vw-input-translator [options] <file>

  --inout <value>
        Creates an input file for binary classification
  -d <value> | --decimals <value>
        Creates an input file for multi-class classification. Each sample will have the selected number of decimals on latitude and longitude coordinates
  <file>
        Source file
----

==== División de datos en conjuntos de entrenamiento y test

Con el objetivo de entrenar al clasificador, se desarrolló un script capaz de, a partir de los datos de entrada que recibiría Vowpal Wabbit, dividir el conjunto en dos para dedicar una parte al proceso de entrenamiento y otra a probar el modelo de datos generados.

Con el objetivo de generar dos conjuntos consistentes, la división se realizó en base a los usuarios, haciendo que un mismo usuario no pudiese formar parte de ambos grupos. Un 80% de los usuarios sería destinado al grupo de entrenamiento, mientras que el 20% restante iría a parar al conjunto de test.
